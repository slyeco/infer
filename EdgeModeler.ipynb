{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "import m2cgen as m2c\n",
    "import os\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"Load the dataset from a CSV file.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    data = pd.read_csv(file_path, delimiter=';')\n",
    "    return data\n",
    "\n",
    "def check_columns(data, required_columns):\n",
    "    \"\"\"Check if required columns are in the dataframe.\"\"\"\n",
    "    missing_columns = [col for col in required_columns if col not in data.columns]\n",
    "    if missing_columns:\n",
    "        raise KeyError(f\"Missing columns in dataset: {missing_columns}\")\n",
    "\n",
    "def generate_log_columns(data):\n",
    "    \"\"\"Generate log10(si) columns.\"\"\"\n",
    "    for i in range(10):\n",
    "        col_name = f's{i}'\n",
    "        if col_name in data.columns:\n",
    "            data[f'log_{col_name}'] = np.log10(data[col_name] + 1)\n",
    "        else:\n",
    "            raise KeyError(f\"Column '{col_name}' not found in the dataset\")\n",
    "    return data\n",
    "\n",
    "def generate_difference_columns(data):\n",
    "    \"\"\"Generate D0, D1, ..., D8 columns.\"\"\"\n",
    "    for i in range(9):\n",
    "        data[f'D{i}'] = data[f'log_s{i+1}'] - data[f'log_s{i}']\n",
    "    return data\n",
    "\n",
    "def encode_labels(data, column):\n",
    "    \"\"\"Encode categorical labels into numerical values.\"\"\"\n",
    "    label_encoder = LabelEncoder()\n",
    "    data[f'{column}_encoded'] = label_encoder.fit_transform(data[column])\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nomi delle colonne del file CSV: Index(['_time', 'vcc', 'vpanel', 'tmp', 'hum', 's0', 's1', 's2', 's3', 's4',\n",
      "       's5', 's6', 's7', 's8', 's9', 'value', 'sensor_name', 'log_s0',\n",
      "       'log_s1', 'log_s2', 'log_s3', 'log_s4', 'log_s5', 'log_s6', 'log_s7',\n",
      "       'log_s8', 'log_s9', 'D0', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7',\n",
      "       'D8', 'value_encoded'],\n",
      "      dtype='object')\n",
      "Valori unici nella colonna 'value_encoded': [0 1]\n"
     ]
    }
   ],
   "source": [
    "# File path\n",
    "file_path = '/home/max/infer/sensordata/merged_dataset_sensors_yellowfire.csv'  # Modify with the correct file path\n",
    "\n",
    "# Load dataset\n",
    "try:\n",
    "    data = load_data(file_path)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "\n",
    "# Check for required columns\n",
    "required_columns = [f's{i}' for i in range(10)] + ['value']\n",
    "try:\n",
    "    check_columns(data, required_columns)\n",
    "except KeyError as e:\n",
    "    print(e)\n",
    "\n",
    "# Generate log columns\n",
    "try:\n",
    "    data = generate_log_columns(data)\n",
    "except KeyError as e:\n",
    "    print(e)\n",
    "\n",
    "# Generate difference columns\n",
    "data = generate_difference_columns(data)\n",
    "\n",
    "# Encode labels\n",
    "try:\n",
    "    data = encode_labels(data, 'value')\n",
    "except KeyError as e:\n",
    "    print(e)\n",
    "\n",
    "print(\"Nomi delle colonne del file CSV:\", data.columns)\n",
    "print(\"Valori unici nella colonna 'value_encoded':\", data['value_encoded'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection and Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature matrix and target vector\n",
    "features = [f'D{i}' for i in range(9)]\n",
    "X = data[features]\n",
    "y = data['value_encoded']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Evaluate Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       646\n",
      "           1       0.98      0.98      0.98       565\n",
      "\n",
      "    accuracy                           0.98      1211\n",
      "   macro avg       0.98      0.98      0.98      1211\n",
      "weighted avg       0.98      0.98      0.98      1211\n",
      "\n",
      "Random Forest Accuracy: 0.9793559042113955\n",
      "Random Forest model saved to '/home/max/infer/sensordata/rf_edge_model.joblib'\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=7, max_depth=12, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "\n",
    "# Save Random Forest model\n",
    "rf_model_path = '/home/max/infer/sensordata/rf_edge_model.joblib'\n",
    "joblib.dump(rf_model, rf_model_path)\n",
    "print(f\"Random Forest model saved to '{rf_model_path}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Evaluate XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       646\n",
      "           1       0.97      0.98      0.98       565\n",
      "\n",
      "    accuracy                           0.98      1211\n",
      "   macro avg       0.98      0.98      0.98      1211\n",
      "weighted avg       0.98      0.98      0.98      1211\n",
      "\n",
      "XGBoost Accuracy: 0.9793559042113955\n",
      "XGBoost model saved to '/home/max/infer/sensordata/xgb_edge_model.joblib'\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate XGBoost model\n",
    "xgb_model = XGBClassifier(max_depth=12, gamma=1, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "print(\"XGBoost Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "\n",
    "# Save XGBoost model\n",
    "xgb_model_path = '/home/max/infer/sensordata/xgb_edge_model.joblib'\n",
    "joblib.dump(xgb_model, xgb_model_path)\n",
    "print(f\"XGBoost model saved to '{xgb_model_path}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Processed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File salvato come '/home/max/infer/sensordata/edge_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save the new dataset to a CSV file\n",
    "output_file = '/home/max/infer/sensordata/edge_dataset.csv'\n",
    "data.to_csv(output_file, index=False)\n",
    "print(f\"File salvato come '{output_file}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export Models to Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Export XGBoost model to Python code\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m python_code \u001b[38;5;241m=\u001b[39m \u001b[43mm2c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport_to_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m python_code_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxgb_edge_model.py\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(python_code_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "File \u001b[0;32m~/infer/venv/lib/python3.10/site-packages/m2cgen/exporters.py:57\u001b[0m, in \u001b[0;36mexport_to_python\u001b[0;34m(model, indent, function_name)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03mGenerates a Python code representation of the given model.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03mcode : string\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     53\u001b[0m interpreter \u001b[38;5;241m=\u001b[39m interpreters\u001b[38;5;241m.\u001b[39mPythonInterpreter(\n\u001b[1;32m     54\u001b[0m     indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[1;32m     55\u001b[0m     function_name\u001b[38;5;241m=\u001b[39mfunction_name\n\u001b[1;32m     56\u001b[0m )\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpreter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/infer/venv/lib/python3.10/site-packages/m2cgen/exporters.py:459\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, interpreter)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_export\u001b[39m(model, interpreter):\n\u001b[1;32m    458\u001b[0m     assembler_cls \u001b[38;5;241m=\u001b[39m get_assembler_cls(model)\n\u001b[0;32m--> 459\u001b[0m     model_ast \u001b[38;5;241m=\u001b[39m \u001b[43massembler_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massemble\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m interpreter\u001b[38;5;241m.\u001b[39minterpret(model_ast)\n",
      "File \u001b[0;32m~/infer/venv/lib/python3.10/site-packages/m2cgen/assemblers/boosting.py:214\u001b[0m, in \u001b[0;36mXGBoostModelAssemblerSelector.assemble\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massemble\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massembler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massemble\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/infer/venv/lib/python3.10/site-packages/m2cgen/assemblers/boosting.py:34\u001b[0m, in \u001b[0;36mBaseBoostingAssembler.assemble\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_classification:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 34\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assemble_bin_class_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_all_estimator_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assemble_multi_class_output(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_all_estimator_params)\n",
      "File \u001b[0;32m~/infer/venv/lib/python3.10/site-packages/m2cgen/assemblers/boosting.py:80\u001b[0m, in \u001b[0;36mBaseBoostingAssembler._assemble_bin_class_output\u001b[0;34m(self, estimator_params)\u001b[0m\n\u001b[1;32m     78\u001b[0m base_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_score \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m---> 80\u001b[0m     base_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mmath\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_base_score\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m     82\u001b[0m expr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assemble_single_output(estimator_params, base_score\u001b[38;5;241m=\u001b[39mbase_score)\n\u001b[1;32m     84\u001b[0m proba_expr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bin_class_convert_output(expr)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "# Export XGBoost model to Python code\n",
    "python_code = m2c.export_to_python(xgb_model)\n",
    "python_code_path = 'xgb_edge_model.py'\n",
    "with open(python_code_path, 'w') as file:\n",
    "    file.write(python_code)\n",
    "print(f\"XGBoost model exported to Python code and saved to '{python_code_path}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export Models to C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Convert XGBoost model to C code\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m c_code \u001b[38;5;241m=\u001b[39m \u001b[43mm2c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport_to_c\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m c_code_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxgb_edge_model.c\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(c_code_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "File \u001b[0;32m~/infer/venv/lib/python3.10/site-packages/m2cgen/exporters.py:81\u001b[0m, in \u001b[0;36mexport_to_c\u001b[0;34m(model, indent, function_name)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03mGenerates a C code representation of the given model.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03mcode : string\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     77\u001b[0m interpreter \u001b[38;5;241m=\u001b[39m interpreters\u001b[38;5;241m.\u001b[39mCInterpreter(\n\u001b[1;32m     78\u001b[0m     indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[1;32m     79\u001b[0m     function_name\u001b[38;5;241m=\u001b[39mfunction_name\n\u001b[1;32m     80\u001b[0m )\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpreter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/infer/venv/lib/python3.10/site-packages/m2cgen/exporters.py:459\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, interpreter)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_export\u001b[39m(model, interpreter):\n\u001b[1;32m    458\u001b[0m     assembler_cls \u001b[38;5;241m=\u001b[39m get_assembler_cls(model)\n\u001b[0;32m--> 459\u001b[0m     model_ast \u001b[38;5;241m=\u001b[39m \u001b[43massembler_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massemble\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m interpreter\u001b[38;5;241m.\u001b[39minterpret(model_ast)\n",
      "File \u001b[0;32m~/infer/venv/lib/python3.10/site-packages/m2cgen/assemblers/boosting.py:214\u001b[0m, in \u001b[0;36mXGBoostModelAssemblerSelector.assemble\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massemble\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massembler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massemble\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/infer/venv/lib/python3.10/site-packages/m2cgen/assemblers/boosting.py:34\u001b[0m, in \u001b[0;36mBaseBoostingAssembler.assemble\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_classification:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 34\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assemble_bin_class_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_all_estimator_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assemble_multi_class_output(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_all_estimator_params)\n",
      "File \u001b[0;32m~/infer/venv/lib/python3.10/site-packages/m2cgen/assemblers/boosting.py:80\u001b[0m, in \u001b[0;36mBaseBoostingAssembler._assemble_bin_class_output\u001b[0;34m(self, estimator_params)\u001b[0m\n\u001b[1;32m     78\u001b[0m base_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_score \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m---> 80\u001b[0m     base_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mmath\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_base_score\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m     82\u001b[0m expr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assemble_single_output(estimator_params, base_score\u001b[38;5;241m=\u001b[39mbase_score)\n\u001b[1;32m     84\u001b[0m proba_expr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bin_class_convert_output(expr)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "# Convert XGBoost model to C code\n",
    "c_code = m2c.export_to_c(xgb_model)\n",
    "c_code_path = 'xgb_edge_model.c'\n",
    "with open(c_code_path, 'w') as file:\n",
    "    file.write(c_code)\n",
    "print(f\"XGBoost model exported to C and saved to '{c_code_path}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
